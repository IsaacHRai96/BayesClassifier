{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isaac Rai CIS 678 \n",
    "## Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the important packages\n",
    "import pandas as pd   \n",
    "import copy as copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn - Estimate Class Probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fish</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Air</th>\n",
       "      <th>Water</th>\n",
       "      <th>Sky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Strong</td>\n",
       "      <td>WarmAir</td>\n",
       "      <td>Warm</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Weak</td>\n",
       "      <td>WarmAir</td>\n",
       "      <td>Warm</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Strong</td>\n",
       "      <td>WarmAir</td>\n",
       "      <td>Warm</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Strong</td>\n",
       "      <td>WarmAir</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>Strong</td>\n",
       "      <td>ColdAir</td>\n",
       "      <td>Cold</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Fish    Wind      Air     Water     Sky\n",
       "0  Yes  Strong  WarmAir      Warm   Sunny\n",
       "1   No    Weak  WarmAir      Warm   Sunny\n",
       "2  Yes  Strong  WarmAir      Warm  Cloudy\n",
       "3  Yes  Strong  WarmAir  Moderate   Rainy\n",
       "4   No  Strong  ColdAir      Cold   Rainy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading in the data frame and renaming columns\n",
    "df = df = pd.read_table('fishing.data', sep = \" \", header = None)\n",
    "df = df.rename(columns={ 0:'Fish', 1:'Wind', 2:'Air', 3:'Water', 4:'Sky'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 0.5714285714285714, 'No': 0.42857142857142855}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inputs: Data - Pandas Data Frame , Class - a String of the name of the class column\n",
    "#Outputs: A dictonary with the name of each class and its prior probability \n",
    "#This function is designed to be robust, and should work with classes of any size\n",
    "def ClassEstimate(Data, Class):\n",
    "    Total = 0\n",
    "    ClassDict = {}\n",
    "    #Getting class names\n",
    "    ClassNames = Data[Class].unique()\n",
    "    #Getting class size for loop\n",
    "    ClassSize = len(Data[Class].unique())\n",
    "    #Getting the values of class\n",
    "    ClassValues = Data[Class].value_counts()\n",
    "    #Getting the total number of observations\n",
    "    for i in range(0, ClassSize):\n",
    "        Total = Total + ClassValues[i]\n",
    "    #Getting proportion of class members to the toal in loop\n",
    "    for i in range(0, ClassSize):\n",
    "        ClassDict[ClassNames[i]] = ClassValues[i]/Total\n",
    "    #Returning dictionary of the class values and their respective prob.\n",
    "    return ClassDict\n",
    "\n",
    "ClassEstimate(df,'Fish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above contains my function for calculating the probability of each class occuring in a data set. I designed the function to be robust so that it can handle classes of any size, and from any dataset. As long as the data is in \n",
    "a Pandas dataframe the function can get the class names and probabilites from the specified class column. I tested\n",
    "the function using the fishing data, and it came up with the same answer we got in class. The output of the function\n",
    "is a dictionary that has key value pairs of each of the class names and its' corresponding probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn - Estimate Attribute Probability Based on Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Wind': {'Strong': 0.3333333333333333, 'Weak': 0.6666666666666666},\n",
       " 'Air': {'WarmAir': 0.3333333333333333, 'ColdAir': 0.6666666666666666},\n",
       " 'Water': {'Warm': 0.16666666666666666,\n",
       "  'Moderate': 0.3333333333333333,\n",
       "  'Cold': 0.5},\n",
       " 'Sky': {'Sunny': 0.3333333333333333,\n",
       "  'Cloudy': 0.0,\n",
       "  'Rainy': 0.6666666666666666}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inputs - Data - Pandas data frame, \n",
    "#   Class - a string containing the name of the class col., \n",
    "#   ClassVal - The desired value of the specified class\n",
    "#Outputs - A dictionary with the attribute names as kays, and another dictionary containing the attribute value and probability\n",
    "def ClassAttEstimate(Data, Class, ClassVal):\n",
    "    #Filtering data frame by class \n",
    "    FilterClass = Data[Data[Class] == ClassVal]\n",
    "    #Dropping the class column\n",
    "    DropClass = FilterClass.drop(columns = Class)\n",
    "    #Dropping class column while keeping all data\n",
    "    EdgeCaseData = Data.drop(columns = Class)\n",
    "    #Getting the column names to store as keys\n",
    "    ColNames = DropClass.columns.unique()\n",
    "    endresult = {}\n",
    "    for i in range(0, len(DropClass.columns)):\n",
    "        #Assigning each of the column names as keys, and a nested dictionary as values\n",
    "        #Reindexed subdictionary with original data set to make sure that every category has an index \n",
    "        #(i.e cloudy has a prob of 0 below since it was not seen by the 'No' class)\n",
    "        endresult[ColNames[i]] = DropClass[ColNames[i]].value_counts(normalize = True ).reindex(EdgeCaseData[ColNames[i]].unique(), fill_value = 0).to_dict()\n",
    "    return endresult\n",
    "ClassAttEstimate(df, 'Fish', 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above calculates the probability of each attribute, based on the given class.My final output is a\n",
    "dictionary with each of the keys being the name of each of the columns in the data set, and the values are another \n",
    "dictionary with the value of each attribute as a key, and its probability as the value. I think the nested\n",
    "dictionary output contains all the data that we need for the classification step, without too much bloat. I\n",
    "considered using tripple nested dictonaries and automatically with the top most parse being each value of the class, \n",
    "but after further consideration I determined that it would make the resulting data structure too complicated. I\n",
    "should be able to get all class values from the output of the function in step one, so I don't need to do that in\n",
    "this function too. The value_counts() function in the Pandas library with the normalize = True argument proved\n",
    "to be invaluable in my code. This would have been much more difficult without it. The reindex() function was also \n",
    "invaluable. I used reindex() with the original data frame to add to each sub dictionary any attribute that was not\n",
    "seen in a particular class. During my validation process I noticed that Sky = 'Cloudy' is not seen in one of the \n",
    "classes, which gave my code problems. I was able to use reindex along with the original data frame as a parameter to \n",
    "have the non seen values still in the sub dictionaries with their probability set to 0. This solves the probelem when a particular attribute value is not seen in one of the classes. The output when I run the \n",
    "function on the Fish data set with the class set to no, yeilds the same values we got doing the calculations by \n",
    "hand in class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify New  Instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 0.02511160714285714, 'No': 0.007936507936507936}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inputs - Instance - A list of strings of the attribute values\n",
    "#       - Class - a string that names the class column\n",
    "#       - Data - A  pandas data frame of the desired data set\n",
    "#Output - A dictionary with the name of each class as the keys, and its probability as the value \n",
    "\n",
    "def BayesClassifier(instance, Class, Data):\n",
    "    TestInstance = instance\n",
    "    #Getting the Class estimates from part one function\n",
    "    ClassEst = ClassEstimate(Data, Class)\n",
    "    #Dropping the class column\n",
    "    DropClass2 = Data.drop(columns = Class)\n",
    "    #Getting the feature names\n",
    "    ColNames2 = DropClass2.columns.unique()\n",
    "    #Getting the Class names\n",
    "    ClassNames2 = list(ClassEst.keys())\n",
    "    ProbDict = {}\n",
    "    Products = {}\n",
    "    #Itterate through every possible class\n",
    "    for i in range(0, len(ClassNames2)):\n",
    "        #Get probability of every class for the class value assigned in this loop\n",
    "        AttProbs = ClassAttEstimate(Data, Class ,ClassNames2[i])\n",
    "        #Storing Class names in dictionary as keys \n",
    "        ProbDict[ClassNames2[i]] = []\n",
    "        #This loop uses two keys to look in the nested dictionary from part two\n",
    "        #The loop looks in the dictionary for the selected class and attribute, and appends the prob to a list. \n",
    "        for j in range(0, len(TestInstance)):\n",
    "            ProbDict[ClassNames2[i]].append(AttProbs[ColNames2[j]][TestInstance[j]])\n",
    "        #appends the class prob. to each class list so that each value in the dictionary is a list of probs\n",
    "        ProbDict[ClassNames2[i]].append(ClassEst[ClassNames2[i]])\n",
    "    #We need to make a copy of the dictionary and store it in another var since python assigns vars by reference\n",
    "    Products = copy.copy(ProbDict)\n",
    "    #This loop multiplys the value of each list together, getting the final prob of each class\n",
    "    for i in range(0, len(Products)):\n",
    "        #Need to convert list into an array to use numpy functions \n",
    "        Products[ClassNames2[i]] = np.array(Products[ClassNames2[i]])\n",
    "        Products[ClassNames2[i]] = Products[ClassNames2[i]].prod()\n",
    "    return Products\n",
    "\n",
    "BayesClassifier(['Strong','WarmAir','Cold','Sunny'], 'Fish', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 0.020089285714285712, 'No': 0.021164021164021163}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesClassifier(['Weak','ColdAir','Moderate','Sunny'], 'Fish', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 0.002511160714285714, 'No': 0.031746031746031744}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesClassifier(['Strong','ColdAir','Cold','Rainy'], 'Fish', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My last function shown above uses the first two functions to calculate the probability of each class using the\n",
    "Naive Bayes algorithm. The way this function more or less works is that it finds the number of classes the data has, \n",
    "and creates a key in a dictionary for each of them. For each corresponding value in the dictionary I store a list of \n",
    "all the probabilities in the instance for the given class (which is the key in the dictionary). I also append the \n",
    "associated class probability to each list. This results in each of the values being a list of all the Multiplicands\n",
    "in the Naive Bayes formula. I convert each list to an array so I can use numpy functions, and multiply everything\n",
    "together to give me the probability of each class. My output is a dictionary of all the class probabilities. I\n",
    "considered outputting the probability lists before multiplication too, but I thought that clutters the output too \n",
    "much. In the future I can go back and add that easily since I stored the dictionary with the multiplicands before \n",
    "I multiplied them all together. During this step I learned that python assigns variables by reference so I needed\n",
    "to make a copy of the object or else it will refer back to the original variable. In the output users can see the probabilities of each class, and select the class with the highest value. Like my other functions this code should\n",
    "work with any data set provided that it is in a Pandas data frame since I use some Pandas functions in it. The \n",
    "input instance to my function must be a list of the attribute values. I chose to simply display the probabilties of each class in the output, so that theoretical users could get an idea of how close the probability of the instance being one class versus the others is. The users can themselves select the class with the highest probability and assign it to the instance. If the user sees that the probabilities are close, it may also allow them to make inferences about the instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Investigation - Scikit Learn Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing ScikitLearn\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yes': 0.02511160714285714, 'No': 0.007936507936507936}\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "#Encoding labels and features\n",
    "wind = le.fit_transform(df.loc[:,'Wind'])\n",
    "air = le.fit_transform(df.loc[:,'Air'])\n",
    "water = le.fit_transform(df.loc[:,'Water'])\n",
    "sky = le.fit_transform(df.loc[:,'Sky'])\n",
    "label =  le.fit_transform(df.loc[:,'Fish'])\n",
    "#Combining encoded features \n",
    "features = zip(wind, air, water, sky)\n",
    "#Creating a NB model \n",
    "NBM = CategoricalNB()\n",
    "\n",
    "#Training the model \n",
    "NBM.fit(list(features), label)\n",
    "\n",
    "#Wind - Strong = 0, Weak = 1\n",
    "#Air - Cold Air = 0, Warm Air = 1\n",
    "#Water cold = 0, moderate = 1, warm = 2\n",
    "#Sky cloudy = 0, rainy = 1, sunnny = 2\n",
    "#Fish No = 0, Yes = 1\n",
    "\n",
    "\n",
    "#Validating results of 'Strong','WarmAir','Cold','Sunny'\n",
    "Validate1 = NBM.predict([[0, 1, 0, 2]]) #'Strong','WarmAir','Cold','Sunny'\n",
    "#Running my classifier\n",
    "Predict1 = BayesClassifier(['Strong','WarmAir','Cold','Sunny'], 'Fish', df)\n",
    "print(Predict1)\n",
    "print(Validate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yes': 0.020089285714285712, 'No': 0.021164021164021163}\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#Validating results of 'Weak','ColdAir','Moderate','Sunny'\n",
    "Validate2 = NBM.predict([[1, 0, 1, 2]])\n",
    "#Running my classifier\n",
    "Predict2 = BayesClassifier(['Weak','ColdAir','Moderate','Sunny'], 'Fish', df)\n",
    "print(Predict2)\n",
    "print(Validate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yes': 0.002511160714285714, 'No': 0.031746031746031744}\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Validating results of 'Strong','ColdAir','Cold','Rainy'\n",
    "Validate3 = NBM.predict([[0, 0, 0, 1]])\n",
    "#Running my classifier\n",
    "Predict3 = BayesClassifier(['Strong','ColdAir','Cold','Rainy'], 'Fish', df)\n",
    "print(Predict3)\n",
    "print(Validate3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yes': 0.005580357142857142, 'No': 0.0}\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#Validating results of 'Weak','ColdAir','Moderate','Sunny'\n",
    "Validate4 = NBM.predict([[1, 1, 1, 0]])\n",
    "#Running my classifier\n",
    "Predict4 = BayesClassifier(['Weak','WarmAir','Moderate','Cloudy'], 'Fish', df)\n",
    "print(Predict4)\n",
    "print(Validate4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify that my Na√Øve Bayes works correctly, I validated some instances against Scikit Learn's Categorical Naieve Bayes Algorithm. My classifier gives the same result as Scikit Learn's in every instance that I tested. During my testing I found that my classifier had a problem when it was given the attribute 'Cloudy'. After some sleuthing I found that my class probability function did not return probabilities for attributes that are not \n",
    "seen in a particular class. In order to remedy this I came up with a way to add the non seen attributes to the sub dictionaries from the output of my second function with their probability set to zero. Once this was addressed, every instance that I verified against Scikit Learn's NB function agreed with my own funtions results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
